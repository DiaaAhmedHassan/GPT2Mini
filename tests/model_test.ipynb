{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440308ee",
   "metadata": {},
   "source": [
    "## Load vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5fa5059-9b52-48d1-a644-6b961b940f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:18.598617Z",
     "iopub.status.busy": "2025-05-23T20:31:18.598359Z",
     "iopub.status.idle": "2025-05-23T20:31:18.607262Z",
     "shell.execute_reply": "2025-05-23T20:31:18.606580Z",
     "shell.execute_reply.started": "2025-05-23T20:31:18.598599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/utilities/merges.txt\n",
      "/kaggle/input/utilities/vocab.json\n",
      "/kaggle/input/utilities/place_holder\n",
      "/kaggle/input/utilities/tiny_stories_vocab.json\n",
      "/kaggle/input/utils/pytorch/default/1/utils.py\n",
      "/kaggle/input/gpt2minimodel/pytorch/default/1/gpt2MiniModel.pt\n",
      "/kaggle/input/gpt2mini/pytorch/default/1/decoder.py\n",
      "/kaggle/input/gpt2mini/pytorch/default/1/gpt2.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a39b-6b7d-42f4-9f5a-52d4dc5a64c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:32.726071Z",
     "iopub.status.busy": "2025-05-23T20:31:32.725310Z",
     "iopub.status.idle": "2025-05-23T20:31:34.749596Z",
     "shell.execute_reply": "2025-05-23T20:31:34.749053Z",
     "shell.execute_reply.started": "2025-05-23T20:31:32.726039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load and tokenize\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "# texts = [sample[\"text\"] for sample in dataset]\n",
    "texts = [sample[\"text\"] for sample in dataset.select(range(50000))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c00b1e3-62d1-4f06-8940-b872eb2a5d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:41.159543Z",
     "iopub.status.busy": "2025-05-23T20:31:41.159278Z",
     "iopub.status.idle": "2025-05-23T20:31:41.163783Z",
     "shell.execute_reply": "2025-05-23T20:31:41.163069Z",
     "shell.execute_reply.started": "2025-05-23T20:31:41.159524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['utilities', 'utils', 'gpt2minimodel', 'gpt2mini']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/kaggle/input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad570624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:44.419029Z",
     "iopub.status.busy": "2025-05-23T20:31:44.418459Z",
     "iopub.status.idle": "2025-05-23T20:31:44.467752Z",
     "shell.execute_reply": "2025-05-23T20:31:44.466923Z",
     "shell.execute_reply.started": "2025-05-23T20:31:44.418990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[('<pad>', 0), ('<unk>', 1), ('<sos>', 2), ('<eos>', 3), ('\"', 4), ('\"\"I', 5), ('\"\"No', 6), ('\"\\'Hello,', 7), ('\"\\'Let\\'s', 8), ('\"\\'Why', 9)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/kaggle/input/utilities/tiny_stories_vocab.json\") as f:\n",
    "    word2idx = json.load(f)\n",
    "    print(type(word2idx))\n",
    "    print(list(word2idx.items())[:10])\n",
    "\n",
    "idx2word = {int(v): k for k, v in word2idx.items()}\n",
    "pad_id = word2idx[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d3a734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:47.040303Z",
     "iopub.status.busy": "2025-05-23T20:31:47.039741Z",
     "iopub.status.idle": "2025-05-23T20:31:47.044208Z",
     "shell.execute_reply": "2025-05-23T20:31:47.043376Z",
     "shell.execute_reply.started": "2025-05-23T20:31:47.040281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8011\n"
     ]
    }
   ],
   "source": [
    "print(word2idx[\"Little\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f33bdd",
   "metadata": {},
   "source": [
    "## Testing Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f48819df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:49.576293Z",
     "iopub.status.busy": "2025-05-23T20:31:49.575704Z",
     "iopub.status.idle": "2025-05-23T20:31:49.585381Z",
     "shell.execute_reply": "2025-05-23T20:31:49.584657Z",
     "shell.execute_reply.started": "2025-05-23T20:31:49.576271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33448]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True # disabling __pycache__\n",
    "sys.path.insert(0, '/kaggle/input/utils/pytorch/default/1/')\n",
    "from utils import Tokenizer\n",
    "# from utils import clean_text\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.upload_vocab(word2idx)\n",
    "tokenizer.encode(\"little\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a74557",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2c22ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:52.097408Z",
     "iopub.status.busy": "2025-05-23T20:31:52.097103Z",
     "iopub.status.idle": "2025-05-23T20:31:52.101768Z",
     "shell.execute_reply": "2025-05-23T20:31:52.100845Z",
     "shell.execute_reply.started": "2025-05-23T20:31:52.097387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# embedding_dim == hidden_size == (D)\n",
    "# embedding_dim % num_heads == 0\n",
    "embedding_dim = 64\n",
    "\n",
    "ff_embedding_dim = 128 # ff_embedding_dim = 4 × embedding_dim\n",
    "max_seq_len = 10\n",
    "dropout = 0.1\n",
    "num_heads = 2\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e73f80c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:54.523554Z",
     "iopub.status.busy": "2025-05-23T20:31:54.522801Z",
     "iopub.status.idle": "2025-05-23T20:31:54.527395Z",
     "shell.execute_reply": "2025-05-23T20:31:54.526529Z",
     "shell.execute_reply.started": "2025-05-23T20:31:54.523527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57374\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c03d0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:31:57.666106Z",
     "iopub.status.busy": "2025-05-23T20:31:57.665820Z",
     "iopub.status.idle": "2025-05-23T20:31:57.745324Z",
     "shell.execute_reply": "2025-05-23T20:31:57.744731Z",
     "shell.execute_reply.started": "2025-05-23T20:31:57.666086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/kaggle/input/gpt2mini/pytorch/default/1')\n",
    "from gpt2 import GPT2Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "encoded = tokenizer.encode(\"dog\")\n",
    "input_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "model = GPT2Model(vocab_size,embedding_dim,ff_embedding_dim,max_seq_len,num_heads,num_layers,dropout = 0.1)\n",
    "\n",
    "# for each position in the sequence, you get a distribution over all vocab tokens.\n",
    "logits = model(input_tensor)  # (B, T, V)\n",
    "\n",
    "# Shift targets for next-token prediction\n",
    "# shift_logits = logits[:, :-1, :].contiguous()\n",
    "# shift_labels = input_tensor[:, 1:].contiguous()\n",
    "\n",
    "# Flatten for CrossEntropyLoss\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# loss = loss_fn(\n",
    "#     shift_logits.view(-1, vocab_size),\n",
    "#     shift_labels.view(-1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fb1ab18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:01.259571Z",
     "iopub.status.busy": "2025-05-23T20:32:01.258887Z",
     "iopub.status.idle": "2025-05-23T20:32:01.263899Z",
     "shell.execute_reply": "2025-05-23T20:32:01.263051Z",
     "shell.execute_reply.started": "2025-05-23T20:32:01.259541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37567, 21502, 12199, 33448, 17846]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.encode(\"one day a little cat\")\n",
    "if hasattr(tokenized_text, \"ids\"):\n",
    "    tokenized_text = tokenized_text.ids\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f9aa510-45a4-4d0d-a422-f2496ec965fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:06.231488Z",
     "iopub.status.busy": "2025-05-23T20:32:06.231220Z",
     "iopub.status.idle": "2025-05-23T20:32:06.236538Z",
     "shell.execute_reply": "2025-05-23T20:32:06.235750Z",
     "shell.execute_reply.started": "2025-05-23T20:32:06.231468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14273844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:13.612101Z",
     "iopub.status.busy": "2025-05-23T20:32:13.611314Z",
     "iopub.status.idle": "2025-05-23T20:32:13.620502Z",
     "shell.execute_reply": "2025-05-23T20:32:13.619652Z",
     "shell.execute_reply.started": "2025-05-23T20:32:13.612066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len):\n",
    "        self.texts = texts\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_id = word2idx[\"<pad>\"]  # Make sure you have a padding token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # Tokenize and convert to IDs\n",
    "        token_ids = self.tokenizer.encode(text)\n",
    "        if hasattr(token_ids, \"ids\"):\n",
    "            token_ids = token_ids.ids\n",
    "        \n",
    "        # Handle sequences that are too short or too long\n",
    "        if len(token_ids) >= self.seq_len:\n",
    "            # Take the first seq_len tokens if too long\n",
    "            token_ids = token_ids[:self.seq_len]\n",
    "        else:\n",
    "            # Pad with <pad> tokens if too short\n",
    "            padding = [self.pad_id] * (self.seq_len - len(token_ids))\n",
    "            token_ids = token_ids + padding\n",
    "        \n",
    "        # Create input and target sequences\n",
    "        x = torch.tensor(token_ids[:-1], dtype=torch.long)  # Input sequence\n",
    "        y = torch.tensor(token_ids[1:], dtype=torch.long)   # Target sequence\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b329a5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8306b2f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:16.933742Z",
     "iopub.status.busy": "2025-05-23T20:32:16.933130Z",
     "iopub.status.idle": "2025-05-23T20:32:16.960796Z",
     "shell.execute_reply": "2025-05-23T20:32:16.959917Z",
     "shell.execute_reply.started": "2025-05-23T20:32:16.933698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from data.dataset import TextDataset\n",
    "\n",
    "# Use longer sequences for testing\n",
    "\n",
    "dataset = CustomTextDataset(texts,tokenizer, seq_len=10)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878e9d5",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae2a2761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:22:39.266495Z",
     "iopub.status.busy": "2025-05-23T20:22:39.266227Z",
     "iopub.status.idle": "2025-05-23T20:22:39.270853Z",
     "shell.execute_reply": "2025-05-23T20:22:39.270047Z",
     "shell.execute_reply.started": "2025-05-23T20:22:39.266477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# embedding_dim == hidden_size == (D)\n",
    "# embedding_dim % num_heads == 0\n",
    "embedding_dim = 64\n",
    "\n",
    "ff_embedding_dim = 128 # ff_embedding_dim = 4 × embedding_dim\n",
    "max_seq_len = 10\n",
    "dropout = 0.1\n",
    "num_heads = 2\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "num_layers = 2\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "005c656a-8ee0-4fc5-9d48-550408ffa76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:24.571934Z",
     "iopub.status.busy": "2025-05-23T20:32:24.571356Z",
     "iopub.status.idle": "2025-05-23T20:32:24.627606Z",
     "shell.execute_reply": "2025-05-23T20:32:24.626695Z",
     "shell.execute_reply.started": "2025-05-23T20:32:24.571912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 9, 57374])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "# #-----Important-------#\n",
    "# # if this cell causes device error comment or remove the comment for the line bellow\n",
    "# x, y = x.to(device), y.to(device)\n",
    "logits = model(x)\n",
    "print(\"Logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52f26da8-7202-489c-ba98-ff29d8df783d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:32:26.735611Z",
     "iopub.status.busy": "2025-05-23T20:32:26.734947Z",
     "iopub.status.idle": "2025-05-23T20:32:26.738800Z",
     "shell.execute_reply": "2025-05-23T20:32:26.738040Z",
     "shell.execute_reply.started": "2025-05-23T20:32:26.735592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "227f32e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:23:14.295748Z",
     "iopub.status.busy": "2025-05-23T20:23:14.295185Z",
     "iopub.status.idle": "2025-05-23T20:25:06.784029Z",
     "shell.execute_reply": "2025-05-23T20:25:06.783391Z",
     "shell.execute_reply.started": "2025-05-23T20:23:14.295726Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 1563/1563 [00:22<00:00, 69.16it/s, loss=6.1627, acc=13.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 8.0956 | Acc: 15.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 1563/1563 [00:21<00:00, 71.64it/s, loss=4.4958, acc=40.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 5.1377 | Acc: 26.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 1563/1563 [00:21<00:00, 71.95it/s, loss=3.5558, acc=62.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 4.2017 | Acc: 48.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 1563/1563 [00:21<00:00, 71.46it/s, loss=3.5620, acc=56.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 3.8499 | Acc: 53.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 1563/1563 [00:21<00:00, 71.44it/s, loss=4.1160, acc=49.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_5.pt\n",
      "Epoch 5 | Loss: 3.6822 | Acc: 55.16%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index = 1, \n",
    "    label_smoothing = 0.1\n",
    ")\n",
    "epochs = 5\n",
    "def train_model(\n",
    "    model,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    device,\n",
    "    vocab_size,\n",
    "    pad_id,\n",
    "    checkpoint_dir=\"check_point\",\n",
    "    checkpoint_freq=5,\n",
    "    start_epoch=0,\n",
    "    history=None\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if history is None:\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'lr_history': []\n",
    "        }\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(progress_bar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask = y != pad_id\n",
    "            correct = (preds[mask] == y[mask]).float().sum()\n",
    "            total = mask.float().sum()\n",
    "            acc = correct / total if total > 0 else 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_correct += correct.item()\n",
    "            epoch_total += total.item()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{acc.item():.2%}\"\n",
    "            })\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        avg_acc = epoch_correct / epoch_total if epoch_total > 0 else 0\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        history['train_acc'].append(avg_acc)\n",
    "        history['lr_history'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        if (epoch + 1) % checkpoint_freq == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "                'accuracy': avg_acc,\n",
    "                'history': history\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Acc: {avg_acc:.2%}\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "trained_model, training_history = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67725a2-3e79-4dd6-b289-22898b815e44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:35:59.272687Z",
     "iopub.status.busy": "2025-05-23T09:35:59.272161Z",
     "iopub.status.idle": "2025-05-23T09:35:59.294833Z",
     "shell.execute_reply": "2025-05-23T09:35:59.294263Z",
     "shell.execute_reply.started": "2025-05-23T09:35:59.272663Z"
    }
   },
   "source": [
    "# after check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6bfb70-5e73-4acb-a3a5-4111f3c89bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T20:56:12.131185Z",
     "iopub.status.busy": "2025-05-23T20:56:12.130678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.14it/s, loss=2.2946, acc=81.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Loss: 2.4576 | Acc: 79.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.11it/s, loss=2.4376, acc=78.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Loss: 2.4499 | Acc: 79.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.41it/s, loss=3.0378, acc=71.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Loss: 2.4401 | Acc: 79.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.90it/s, loss=2.2186, acc=79.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Loss: 2.4322 | Acc: 79.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.07it/s, loss=2.2761, acc=84.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_55.pt\n",
      "Epoch 55 | Loss: 2.4224 | Acc: 79.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.52it/s, loss=2.0368, acc=85.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Loss: 2.4158 | Acc: 80.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.75it/s, loss=1.7790, acc=93.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Loss: 2.4048 | Acc: 80.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.20it/s, loss=2.2738, acc=82.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Loss: 2.3987 | Acc: 80.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.08it/s, loss=2.2739, acc=84.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Loss: 2.3907 | Acc: 80.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.06it/s, loss=2.3555, acc=79.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_60.pt\n",
      "Epoch 60 | Loss: 2.3811 | Acc: 80.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.13it/s, loss=2.4667, acc=80.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Loss: 2.3726 | Acc: 80.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.86it/s, loss=2.5729, acc=77.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Loss: 2.3652 | Acc: 81.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.87it/s, loss=1.9260, acc=86.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Loss: 2.3587 | Acc: 81.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.21it/s, loss=2.3778, acc=83.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Loss: 2.3496 | Acc: 81.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.27it/s, loss=2.4049, acc=81.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_65.pt\n",
      "Epoch 65 | Loss: 2.3395 | Acc: 81.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.97it/s, loss=2.7567, acc=75.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Loss: 2.3327 | Acc: 81.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.96it/s, loss=2.3259, acc=81.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Loss: 2.3246 | Acc: 81.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.10it/s, loss=2.0924, acc=86.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Loss: 2.3166 | Acc: 81.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.04it/s, loss=2.4571, acc=82.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Loss: 2.3104 | Acc: 82.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 1563/1563 [00:23<00:00, 65.97it/s, loss=2.0437, acc=85.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_70.pt\n",
      "Epoch 70 | Loss: 2.3024 | Acc: 82.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.93it/s, loss=2.4928, acc=78.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Loss: 2.2937 | Acc: 82.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.36it/s, loss=2.3723, acc=84.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Loss: 2.2861 | Acc: 82.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.88it/s, loss=2.2206, acc=82.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Loss: 2.2785 | Acc: 82.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.97it/s, loss=1.9068, acc=90.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Loss: 2.2703 | Acc: 82.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.96it/s, loss=2.4729, acc=79.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_75.pt\n",
      "Epoch 75 | Loss: 2.2603 | Acc: 83.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.25it/s, loss=2.2777, acc=78.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Loss: 2.2522 | Acc: 83.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 1563/1563 [00:23<00:00, 66.99it/s, loss=1.9663, acc=90.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Loss: 2.2442 | Acc: 83.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.04it/s, loss=2.3313, acc=83.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Loss: 2.2342 | Acc: 83.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.01it/s, loss=2.1276, acc=87.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Loss: 2.2265 | Acc: 83.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 1563/1563 [00:23<00:00, 67.20it/s, loss=1.8614, acc=90.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to check_point/checkpoint_epoch_80.pt\n",
      "Epoch 80 | Loss: 2.2160 | Acc: 83.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100:  68%|██████▊   | 1057/1563 [00:15<00:07, 67.62it/s, loss=1.9676, acc=89.58%]"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index = 1, \n",
    "    label_smoothing = 0.1\n",
    ")\n",
    "checkpoint_path = \"check_point/checkpoint_epoch_50.pt\"  # Adjust path if needed\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# === Load model weights ===\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# === Re-create the optimizer and load its state ===\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# === Extract training state ===\n",
    "start_epoch = checkpoint['epoch']  # This will be 10\n",
    "history = checkpoint['history']\n",
    "\n",
    "trained_model, training_history = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=100,  # final epoch number you want to reach\n",
    "    device=device,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=0,\n",
    "    checkpoint_dir=\"check_point\",\n",
    "    checkpoint_freq=5,\n",
    "    start_epoch=start_epoch,   # resume from epoch 60\n",
    "    history=history            # continue the same history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4605e1-f313-4e65-b199-b06ba0a7ba13",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e68861a-8318-45df-b139-e101888a7d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:33:59.547217Z",
     "iopub.status.busy": "2025-05-23T18:33:59.546868Z",
     "iopub.status.idle": "2025-05-23T18:34:01.664052Z",
     "shell.execute_reply": "2025-05-23T18:34:01.663003Z",
     "shell.execute_reply.started": "2025-05-23T18:33:59.547193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")\n",
    "test_texts = [sample[\"text\"] for sample in test_dataset]\n",
    "\n",
    "test_dataset = CustomTextDataset(test_texts,tokenizer, seq_len=10)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0ae724e-4448-4da8-8d9f-f38bc258a218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:34:07.335935Z",
     "iopub.status.busy": "2025-05-23T18:34:07.335555Z",
     "iopub.status.idle": "2025-05-23T18:34:07.343915Z",
     "shell.execute_reply": "2025-05-23T18:34:07.342895Z",
     "shell.execute_reply.started": "2025-05-23T18:34:07.335911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_loop(model, dataloader, criterion, device, vocab_size, pad_id):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # 1) Forward\n",
    "            logits = model(x)                   # [batch, seq_len, vocab_size]\n",
    "            batch_size, seq_len, vocab_size = logits.shape\n",
    "\n",
    "            # 2) Flatten\n",
    "            logits_flat = logits.view(-1, vocab_size)  # [batch*seq_len, vocab_size]\n",
    "            y_flat      = y.view(-1)                   # [batch*seq_len]\n",
    "\n",
    "            # 3) Loss\n",
    "            loss = criterion(logits_flat, y_flat)\n",
    "\n",
    "            # 4) Metrics\n",
    "            mask = (y_flat != pad_id)                  # ignore padding\n",
    "            preds = logits_flat.argmax(dim=-1)         # [batch*seq_len]\n",
    "            correct = (preds[mask] == y_flat[mask]).sum().item()\n",
    "            total = mask.sum().item()\n",
    "\n",
    "            # 5) Accumulate\n",
    "            total_loss    += loss.item()\n",
    "            total_correct += correct\n",
    "            total_tokens  += total\n",
    "\n",
    "    # 6) Averages\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else 0.0\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d80e5d-abce-489c-919b-357cc42731df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:34:12.105661Z",
     "iopub.status.busy": "2025-05-23T18:34:12.105279Z",
     "iopub.status.idle": "2025-05-23T18:34:12.728994Z",
     "shell.execute_reply": "2025-05-23T18:34:12.727328Z",
     "shell.execute_reply.started": "2025-05-23T18:34:12.105634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (embeddings): EmbeddingLayer(\n",
       "    (token_embedding): Embedding(19716, 64)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x DecoderLayer(\n",
       "      (attn): ResidualBlock(\n",
       "        (sub_layer): MultiHeadSelfAttention(\n",
       "          (qkv_proj): Linear(in_features=64, out_features=192, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): ResidualBlock(\n",
       "        (sub_layer): FeedForward(\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=64, out_features=19716, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/gpt2minimodel/pytorch/default/1/gpt2MiniModel.pt\"\n",
    "\n",
    "check_point = torch.load(model_path, map_location=device)\n",
    "\n",
    "model.load_state_dict(check_point['model_state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe804a10-3bde-468b-8c33-38044d356850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:16:42.132202Z",
     "iopub.status.busy": "2025-05-23T18:16:42.131919Z",
     "iopub.status.idle": "2025-05-23T18:16:45.707069Z",
     "shell.execute_reply": "2025-05-23T18:16:45.706296Z",
     "shell.execute_reply.started": "2025-05-23T18:16:42.132181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 688/688 [00:03<00:00, 192.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7535\n",
      "Test Accuracy: 88.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = test_loop(\n",
    "    model, \n",
    "    test_dataloader,\n",
    "    nn.CrossEntropyLoss(ignore_index=1, label_smoothing=0.1), \n",
    "    device=device,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_id=1   \n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72624f35",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0701cbb9-9eab-41a9-8e61-3646753b6d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:01:18.091567Z",
     "iopub.status.busy": "2025-05-23T18:01:18.091293Z",
     "iopub.status.idle": "2025-05-23T18:05:56.191150Z",
     "shell.execute_reply": "2025-05-23T18:05:56.190542Z",
     "shell.execute_reply.started": "2025-05-23T18:01:18.091548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from tokenizers import  Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "# tokenizer = Tokenizer(models.BPE())\n",
    "# tokenizer.pre_tokenizers = pre_tokenizers.Whitespace()\n",
    "# trainer = trainers.BpeTrainer(vocab_size=10000, special_tokens=[\"<pad>\", \"<unk>\"])\n",
    "# tokenizer.train(files=[\"tiny_stories.txt\"], trainer=trainer)\n",
    "# tokenizer.save(\"bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0575b6cc-22ed-4e05-9d49-b4c8068791c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:08:28.263654Z",
     "iopub.status.busy": "2025-05-23T18:08:28.262744Z",
     "iopub.status.idle": "2025-05-23T18:08:28.289219Z",
     "shell.execute_reply": "2025-05-23T18:08:28.288353Z",
     "shell.execute_reply.started": "2025-05-23T18:08:28.263629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one da y a  Little  G ir l  went to  school\n"
     ]
    }
   ],
   "source": [
    "# from tokenizers import Tokenizer\n",
    "# tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")\n",
    "\n",
    "# ids = tokenizer.encode(\"one day a Little Girl went to school\").ids\n",
    "# decoded = tokenizer.decode(ids)\n",
    "# print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ef1e000-75f3-40bc-8d99-7989048c30b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:11:51.956492Z",
     "iopub.status.busy": "2025-05-23T18:11:51.955600Z",
     "iopub.status.idle": "2025-05-23T18:11:51.960608Z",
     "shell.execute_reply": "2025-05-23T18:11:51.959837Z",
     "shell.execute_reply.started": "2025-05-23T18:11:51.956459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1475, 3804, 1119, 1337, 3007]\n"
     ]
    }
   ],
   "source": [
    "# ids = tokenizer.encode(\"one day a cat went to school\").ids\n",
    "# print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb67ce",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-22T15:18:31.986981Z",
     "iopub.status.idle": "2025-05-22T15:18:31.987290Z",
     "shell.execute_reply": "2025-05-22T15:18:31.987149Z",
     "shell.execute_reply.started": "2025-05-22T15:18:31.987134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# GPT2Config.vocab_size = len(word2idx)\n",
    "# model = GPT2Model(GPT2Config())\n",
    "# model.load_state_dict(torch.load(\"gpt2_tiny.pth\", map_location=\"cpu\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945b2634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:34:18.364470Z",
     "iopub.status.busy": "2025-05-23T18:34:18.364152Z",
     "iopub.status.idle": "2025-05-23T18:34:18.371115Z",
     "shell.execute_reply": "2025-05-23T18:34:18.369849Z",
     "shell.execute_reply.started": "2025-05-23T18:34:18.364445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(prompt, max_new_tokens=50):\n",
    "    input_ids = tokenizer.encode(prompt)\n",
    "    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)  # [1, T]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = model(input_tensor)  # [1, T, vocab]\n",
    "            next_token_logits = logits[:, -1, :]  # last position\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)  # [1, 1]\n",
    "            input_tensor = torch.cat([input_tensor, next_token], dim=1)  # grow the sequence\n",
    "\n",
    "    return tokenizer.decode(input_tensor[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f34f3137-6634-424c-bd41-9cb7f73ed4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:34:21.391836Z",
     "iopub.status.busy": "2025-05-23T18:34:21.391509Z",
     "iopub.status.idle": "2025-05-23T18:34:21.397057Z",
     "shell.execute_reply": "2025-05-23T18:34:21.395889Z",
     "shell.execute_reply.started": "2025-05-23T18:34:21.391812Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[495, 1131, 69, 9661, 3, 2044, 17497]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"one day a cat went to school\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b63b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T18:34:24.091269Z",
     "iopub.status.busy": "2025-05-23T18:34:24.090915Z",
     "iopub.status.idle": "2025-05-23T18:34:24.191830Z",
     "shell.execute_reply": "2025-05-23T18:34:24.190549Z",
     "shell.execute_reply.started": "2025-05-23T18:34:24.091243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = \"once upon time a little cat called\"\n",
    "print(generate_text(prompt, max_new_tokens=16))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7497974,
     "sourceId": 11925781,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 353615,
     "modelInstanceId": 332687,
     "sourceId": 407160,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 355224,
     "modelInstanceId": 334232,
     "sourceId": 409060,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 355398,
     "modelInstanceId": 334374,
     "sourceId": 409247,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
